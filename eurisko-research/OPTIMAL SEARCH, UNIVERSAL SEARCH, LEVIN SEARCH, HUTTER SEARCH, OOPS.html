<html><head>
<meta http-equiv="content-type" content="text/html; charset=windows-1252"><title>OPTIMAL SEARCH, UNIVERSAL SEARCH, LEVIN SEARCH, HUTTER SEARCH, OOPS</title>
</head><body link="#770000" vlink="#550000" bgcolor="#224466">
<center><br><br>
<table width="675" bgcolor="#ffffff" border="0" cellpadding="25" cellspacing="0">
<tbody><tr><td bgcolor="#dddddd"><center>
<h2>
OPTIMAL UNIVERSAL SEARCH
</h2>
</center></td></tr>
<tr> <td bgcolor="#ffffff"> <center>
<table width="625" bgcolor="#ffffff" cellpadding="10" cellspacing="0">
<tbody><tr>
<td>
<p>


Unbeknownst to many computer scientists (including some who wrote
books on search algorithms) there exists a very
simple search method with an astonishing theoretical property: for a broad 
class of non-incremental search problems, universal search or Levin Search
(LS) has the optimal order of computational complexity
(L. Levin,  Problems of Information Transmission, 9(3):265--266, 1973). 
For example, suppose there is an unknown algorithm that solves
some inversion problem in O(f(n)) steps, where f is a total recursive
function and n a positive
integer representing problem size.  Then LS will solve the
same problem in at most O(f(n)) steps.  Unfortunately, however, 
the constant factor buried in the O() notation
may be huge.


</p></td></tr><tr>
<td bgcolor="#dddddd">
Recently 
<a href="http://www.idsia.ch/%7Emarcus/"> Marcus Hutter</a>
(funded through Schmidhuber's SNF research grant "Unification of Universal
Induction and Sequential Decision Theory") was
able to derive an even more general optimal search algorithm
which actually reduces the constant factor down to less than 5
(at the expense of introducing an unknown, problem
 class-specific additive constant):

<p>
</p><dt>1.  M. Hutter.
<a href="ftp://ftp.idsia.ch/pub/techrep/IDSIA-16-00.ps.gz"> The Fastest and
Shortest Algorithm for All Well-Defined Problems.</a> International
Journal of Foundations of Computer Science, 13(3):431-443, 2002.

</dt></td></tr><tr>
<td>


<dt>2.  
Levin's and Hutter's asymptotically optimal methods 
are non-incremental and
ignore the huge unknown constants. To overcome this drawback,
Schmidhuber extended the principles of non-incremental universal 
search to build a novel, optimally fast, incremental learner that is able to
improve itself through experience.  The 
<a href="http://people.idsia.ch/%7Ejuergen/oops.html"> Optimal Ordered Problem Solver </a> 
(OOPS, J. Schmidhuber, July 2002, MLJ 2004) 
searches for a universal algorithm that solves
each task in a sequence of tasks. It continually organizes and exploits 
previously found solutions to earlier tasks, efficiently
searching not only the space of domain-specific algorithms, 
but also the space of search algorithms. 
It can be used for efficient proof search by the even more general
<a href="http://people.idsia.ch/%7Ejuergen/goedelmachine.html"> Gödel machine.</a> 


</dt></td></tr><tr>
<td bgcolor="#dddddd">

First applications of LS and related methods were earlier described in:

<p>
</p><dt>3.
J. Schmidhuber.
<a href="ftp://ftp.idsia.ch/pub/juergen/loconet.ps.gz">
Discovering neural nets with low Kolmogorov complexity
and high generalization capability.
</a>
Neural Networks, 10(5):857-873, 1997 (123 K).
<a href="ftp://ftp.idsia.ch/pub/juergen/loconet.pdf">
PDF
</a>,
<a href="http://people.idsia.ch/%7Ejuergen/loconet/nngen.html">
HTML
</a>
<p>

</p><p>
</p></dt><dt>4.  J. &nbsp;Schmidhuber.
<a href="ftp://ftp.idsia.ch/pub/juergen/ml95kol.ps.gz">
Discovering solutions with  low Kolmogorov complexity
and high generalization capability.
</a>
In A.&nbsp;Prieditis and S.&nbsp;Russell, editors, <em>Machine Learning:
Proceedings of the Twelfth International Conference</em>, pages 488-496. Morgan
Kaufmann Publishers, San Francisco, CA, 1995.
<a href="ftp://ftp.idsia.ch/pub/juergen/icmlkolmogorov.pdf"> PDF </a>.
<a href="http://people.idsia.ch/%7Ejuergen/icmlkolmogorov/icmlkolmogorov.html"> HTML.</a>

</dt></td></tr><tr>
<td>

To automatically generate computer programs 
solving complex problems in incremental settings,
Schmidhuber also introduced Adaptive Levin Search (ALS):


<p>
</p><dt>5.
J. Schmidhuber, J. Zhao, and  M. Wiering.
<a href="ftp://ftp.idsia.ch/pub/juergen/bias.ps.gz">
Shifting inductive bias with success-story algorithm,
adaptive Levin search, and incremental self-improvement.
</a>
Machine Learning 28:105-130, 1997.
<a href="ftp://ftp.idsia.ch/pub/juergen/mljssalevin.pdf"> PDF </a>.
<a href="http://people.idsia.ch/%7Ejuergen/mljssalevin"> Flawed HTML.</a>


<p>
</p></dt><dt>6.  M. Wiering and J. Schmidhuber.
<a href="ftp://ftp.idsia.ch/pub/juergen/ml_levin_eira.ps.gz">
Solving POMDPs using Levin search and EIRA.
</a>
In L. Saitta, ed.,
<em>Machine Learning:
Proceedings of the 13th International Conference</em>,
pages 534-542,
Morgan Kaufmann Publishers, San Francisco, CA, 1996.
<a href="ftp://ftp.idsia.ch/pub/juergen/icmllevineira.pdf"> PDF </a>.
<a href="http://people.idsia.ch/%7Ejuergen/icmllevineira/icmllevineira.html"> HTML.</a>



 
</dt></td></tr></tbody></table> </center></td></tr><tr> <td> <center>
<a href="http://www.idsia.ch/%7Ejuergen">
<img src="OPTIMAL%20SEARCH,%20UNIVERSAL%20SEARCH,%20LEVIN%20SEARCH,%20HUTTER%20SEARCH,%20OOPS_files/homebar7.jpg" alt="*" width="615" align="MIDDLE" border="0"> </a>
</center> </td></tr></tbody></table> <br> <br> <br> <br>

</center></body></html>